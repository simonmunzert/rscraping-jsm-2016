install.packages(c("BH", "broom", "devtools", "dplyr", "evaluate", "fields", "formatR", "geepack", "geosphere", "git2r", "highr", "httr", "jsonlite", "knitr", "lazyeval", "lme4", "MCMCpack", "mime", "miniCRAN", "nlme", "plyr", "psych", "quantreg", "RcppArmadillo", "rgdal", "rgeos", "rmarkdown", "rstudioapi", "rvest", "slam", "sp", "spatstat", "spdep", "survival", "tidyr", "useful", "VGAM", "WikidataR", "WikipediR", "withr", "XLConnect", "XLConnectJars", "xml2", "Zelig", "zoo"))
source("00-course-setup.r")
source("00-course-setup.r")
source("00-course-setup.r")
wd <- getwd()
url <- "http://www.iea.org/policiesandmeasures/renewableenergy/"
browseURL(url)
content <- read_html(url)
checkForServer()
startServer()
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
# open connection; Firefox window should pop up
remDr$open()
remDr$open()
checkForServer()
# start server
startServer()
# connect to server
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
# open connection; Firefox window should pop up
remDr$open()
remDr$navigate(url)
# open regions menu
css <- 'div.form-container:nth-child(2) > ul:nth-child(2) > li:nth-child(1) > span:nth-child(1)'
regionsElem <- remDr$findElement(using = 'css', value = css)
openRegions <- regionsElem$clickElement() # click on button
# open regions menu
css <- 'div.form-container:nth-child(2) > ul:nth-child(2) > li:nth-child(1) > span:nth-child(1)'
regionsElem <- remDr$findElement(using = 'css', value = css)
openRegions <- regionsElem$clickElement() # click on button
remDr$navigate(url)
# open regions menu
css <- 'div.form-container:nth-child(2) > ul:nth-child(2) > li:nth-child(1) > span:nth-child(1)'
regionsElem <- remDr$findElement(using = 'css', value = css)
openRegions <- regionsElem$clickElement() # click on button
css <- 'div.form-container:nth-child(2) > ul:nth-child(2) > li:nth-child(1) > span:nth-child(1)'
regionsElem <- remDr$findElement(using = 'css', value = css)
openRegions <- regionsElem$clickElement() # click on button
css <- 'div.form-container:nth-child(2) > ul:nth-child(2) > li:nth-child(1) > ul:nth-child(3) > li:nth-child(5) > label:nth-child(1) > input:nth-child(1)'
euElem <- remDr$findElement(using = 'css', value = css)
selectEU <- euElem$clickElement() # click on button
css <- 'div.form-container:nth-child(6) > select:nth-child(2)'
fromDrop <- remDr$findElement(using = 'css', value = css)
clickFrom <- fromDrop$clickElement() # click on drop-down menu
writeFrom <- fromDrop$sendKeysToElement(list("2000")) # enter start year
css <- 'div.form-container:nth-child(6) > select:nth-child(3)'
toDrop <- remDr$findElement(using = 'css', value = css)
clickTo <- toDrop$clickElement() # click on drop-down menu
writeTo <- toDrop$sendKeysToElement(list("2010")) # enter end year
# click on search button
css <- '#main > div:nth-child(1) > form:nth-child(4) > button:nth-child(14)'
searchElem <- remDr$findElement(using = 'css', value = css)
resultsPage <- searchElem$clickElement() # click on button
output <- remDr$getPageSource(header = TRUE)
write(output[[1]], file = "iea-renewables.html")
remDr$closeServer()
# parse index table
content <- read_html("iea-renewables.html", encoding = "utf8")
tabs <- html_table(content, fill = TRUE)
tab <- head(tabs[[1]])
names(tab) <- c("title", "country", "year", "status", "type", "target")
head(tab)
source("rselenium-2048.r") # by Mark T. Patterson
startServer()
# connect to server
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
# open connection; Firefox window should pop up
remDr$open()
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
# open connection; Firefox window should pop up
remDr$open()
remDr$navigate(url)
source("rselenium-2048.r") # by Mark T. Patterson
grand.play()
Sys.setenv(LANG = "en")
kblaad
url <- "http://www.starbucks.com/store-locator/search/location/chicago"
checkForServer()
startServer()
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
remDr$open()
remDr$navigate(url)
css <- 'span.icon:nth-child(2)'
regionsElem <- remDr$findElement(using = 'css', value = css)
openRegions <- regionsElem$clickElement() # click on button
css <- '#find_wf'
click_elem <- remDr$findElement(using = 'css', value = css)
open_elem <- click_elem$clickElement() # click on button
output <- remDr$getPageSource(header = TRUE)
output <- remDr$getPageSource(header = TRUE)
# navigate to page
checkForServer()
startServer()
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
remDr$open()
remDr$navigate(url)
# actions on page
css <- 'span.icon:nth-child(2)'
click_elem <- remDr$findElement(using = 'css', value = css)
open_elem <- click_elem$clickElement() # click on button
css <- '#find_wf'
click_elem <- remDr$findElement(using = 'css', value = css)
open_elem <- click_elem$clickElement() # click on button
output <- remDr$getPageSource(header = TRUE)
output <- remDr$getPageSource()
getPageSource
devtools::install_github("ropensci/RSelenium")
# navigate to page
checkForServer()
startServer()
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName = "firefox")
remDr$open()
remDr$navigate(url)
# actions on page
css <- 'span.icon:nth-child(2)'
click_elem <- remDr$findElement(using = 'css', value = css)
open_elem <- click_elem$clickElement() # click on button
css <- '#find_wf'
click_elem <- remDr$findElement(using = 'css', value = css)
open_elem <- click_elem$clickElement() # click on button
output <- remDr$getPageSource(header = TRUE)
write(output[[1]], file = "starbucks-chicago.html")
remDr$closeServer()
content <- read_html("starbucks-chicago.html", encoding = "utf8")
store_names <- html_nodes(content, ".store-name") %>% html_text()
store_names
store_addresses <- html_nodes(content, ".address li:nth-child(1)") %>% html_text()
store_addresses
locations <- paste0(store_addresses, ", Chicago, IL")
locations
pos <- geocode(locations, source = "google")
head(pos)
starbucks_map <- get_map(location=c(lon=mean(pos$lon), lat=mean(pos$lat)), zoom="auto", maptype="hybrid")
p <- ggmap(starbucks_map) + geom_point(data=pos, aes(x=lon, y=lat), col="red", size=3)
p
starbucks_map <- get_map(location=c(lon=mean(pos$lon), lat=mean(pos$lat)), zoom=13, maptype="hybrid")
p <- ggmap(starbucks_map) + geom_point(data=pos, aes(x=lon, y=lat), col="red", size=3)
p
browseURL("http://ropensci.org/")
browseURL("http://arxiv.org/help/api/index")
browseURL("http://arxiv.org/help/api/user-manual")
browseURL("http://export.arxiv.org/api/query?search_query=all:forecast")
library(xml2)
forecast <- read_xml("http://export.arxiv.org/api/query?search_query=all:forecast")
forecast
xml_text(forecast)
xml_find_all(forecast, "//x:author", ns = xml_ns(x"http://www.w3.org/2005/Atom"))
xml_find_all(forecast, "//x:author", ns = xml_ns("http://www.w3.org/2005/Atom"))
xml_find_all(forecast, "//x:author")
browseURL("http://export.arxiv.org/api/query?search_query=all:forecast")
xml_find_all(forecast, "//author")
xml_find_all(forecast, "//author", ns = xml_ns(forecast))
xml_ns(forecast)
x <- read_xml('
<root xmlns:f = "http://foo.com" xmlns:g = "http://bar.com">
<f:doc><g:baz /></f:doc>
<f:doc><g:baz /></f:doc>
</root>
')
xml_find_all(x, ".//f:doc")
xml_find_all(x, ".//f:doc", xml_ns(x))
xml_find_all(forecast, "//d1:author", ns = xml_ns(forecast))
authors <- xml_find_all(forecast, "//d1:author", ns = xml_ns(forecast))
authors %>% xml_text()
source("00-course-setup.r")
wd <- getwd()
source("00-course-setup.r")
wd <- getwd()
authors <- xml_find_all(forecast, "//d1:author", ns = xml_ns(forecast))
authors %>% xml_text()
ls("package:aRxiv")
arxiv_df <- arxiv_search(query = "forecast", limit = 10, output_format = "data.frame")
View(arxiv_df)
query_terms
query_terms
arxiv_count('au:"Gary King"')
?arxiv_search
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[201001010000 TO 201701012400], limit = 10, output_format = "data.frame")
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[201001010000 TO 201701012400]", limit = 10, output_format = "data.frame")
View(arxiv_df)
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[201001010000 TO 201601012400]", limit = 10, output_format = "data.frame")
View(arxiv_df)
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[201401010000 TO 201601012400]", limit = 10, output_format = "data.frame")
View(arxiv_df)
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[201601010000 TO 201701012400]", limit = 50, output_format = "data.frame")
View(arxiv_df)
ls("package:aRxiv")
lsf.str("package:aRxiv")
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[2016 TO 2017]", limit = 50, output_format = "data.frame")
View(arxiv_df)
arxiv_df <- arxiv_search(query = "forecast AND submittedDate:[2016 TO 2017]", limit = 1000, output_format = "data.frame")
View(arxiv_df)
arxiv_count('abs:"political" AND submittedDate:[2010 TO 2017]')
arxiv_count('abs:"political" AND submittedDate:[2016 TO 2017]')
polsci_articles <- arxiv_search('abs:"political" AND submittedDate:[2016 TO 2017]', limit = 1000)
View(polsci_articles)
library(pageviews)
ls("package:pageviews")
?article_pageviews
trump_views <- article_pageviews(project = "en.wikipedia", article = "Donald Trump", user_type = "user", start = "2015010100", end = "20160720")
View(trump_views)
trump_views <- article_pageviews(project = "en.wikipedia", article = "Donald Trump", user_type = "user", start = "2016010100", end = "20160720")
View(trump_views)
?pageview_timestamps
clinton_views <- article_pageviews(project = "en.wikipedia", article = "Hillary Clinton", user_type = "user", start = "2016010100", end = "20160720")
head(trump_views)
plot(trump_views$views)
?ts
plot(trump_views$timestamp, trump_views$views)
as.Date(trump_views$timestamp)
?ymd
library(lubridate)
ymd(trump_views$timestamp)
ymd_h(trump_views$timestamp)
plot(ymd_h(trump_views$timestamp), trump_views$views)
plot(ymd_h(trump_views$timestamp), trump_views$views, type = "l")
lines(ymd_h(clinton_views$timestamp), clinton_views$views, col = "blue")
plot(ymd_h(trump_views$timestamp), trump_views$views, col = "red", type = "l")
lines(ymd_h(clinton_views$timestamp), clinton_views$views, col = "blue")
hist(clinton_views$views)
plot(ymd_h(trump_views$timestamp), trump_views$views, col = "red", type = "l")
lines(ymd_h(clinton_views$timestamp), clinton_views$views, col = "blue")
View(trump_views)
browseURL("http://www.enigma.io/")
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
setup_twitter_oauth(api_key,api_secret)
source("00-course-setup.r")
wd <- getwd()
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
setup_twitter_oauth(api_key,api_secret)
tweets <- searchTwitter(searchString = "Trump", n=25, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, retryOnRateLimit=120)
setup_twitter_oauth(api_key,api_secret)
install.packages("httpuv")
setup_twitter_oauth(api_key,api_secret)
tweets <- searchTwitter(searchString = "Trump", n=25, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, retryOnRateLimit=120)
tweets_df <- twListToDF(tweets)
head(tweets_df)
source("00-course-setup.r")
wd <- getwd()
# negotiate credentials
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
setup_twitter_oauth(api_key,api_secret)
tweets <- searchTwitter(searchString = "Trump", n=25, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, retryOnRateLimit=120)
tweets_df <- twListToDF(tweets)
head(tweets_df)
names(tweets_df)
user <- getUser("RDataCollection")
user$name
user$lastStatus
user$followersCount
user$statusesCount
user_followers <- user$getFollowers()
user_friends <- user$getFriends()
user_timeline <- userTimeline(user, n=20)
timeline_df <- twListToDF(user_timeline)
head(timeline_df)
x <- GET("https://google.com")
x
j1 = GET(“http://www.omdbapi.com/?t=iron%20man%202&r=json”)
j1 = GET("http://www.omdbapi.com/?t=iron%20man%202&r=json”
)
j1 = GET("http://www.omdbapi.com/?t=iron%20man%202&r=json")
content(j1, as = “text”)
content(j1, as =  "text")
content(j1, as =  "parsed")
?content
j1 = GET("http://www.omdbapi.com/?t=iron%20man%202&r=xml")
content(j1, as =  "text")
content(j1, as =  "parsed")
browseURL("http://www.omdbapi.com/")
title <- "Groundhog Day" %>% URLencode()
title
url <- paste0("http://www.omdbapi.com/?t=", title)
url <- paste0("http://www.omdbapi.com/?t=", title, "&tomatoes=true")
url
omdb_res = GET(url)
content(omdb_res, as =  "parsed")
url <- paste0("http://www.omdbapi.com/?s=", title)
omdb_res = GET(url)
content(omdb_res, as =  "parsed")
res_list <- content(omdb_res, as =  "parsed")
class(res_list)
unlist(res_list)
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
content(omdb_res, as =  "parsed")
res_list <- content(omdb_res, as =  "parsed")
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
url <- paste0("http://www.omdbapi.com/?s=", title)
omdb_res = GET(url)
content(omdb_res, as =  "parsed")
res_list <- content(omdb_res, as =  "parsed")
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
res_list
res_list %>% unlist()
url <- paste0("http://www.omdbapi.com/?s=", title)
omdb_res = GET(url)
res_list <- content(omdb_res, as =  "parsed")
res_list
res_list %>% unlist()
raw_data <- fromJSON(omdb_res, flatten = TRUE)
raw_data <- jsonlite::fromJSON(omdb_res, flatten = TRUE)
omdb_res
raw_data <- content(omdb_res, as = "text"), %>% jsonlite::fromJSON(flatten = TRUE)
raw_data <- content(omdb_res, as = "text") %>% jsonlite::fromJSON(flatten = TRUE)
raw_data
res_list <- content(omdb_res, as = "text") %>% jsonlite::fromJSON(flatten = TRUE)
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
omdb_res = GET(url)
res_list <- content(omdb_res, as = "text") %>% jsonlite::fromJSON(flatten = TRUE)
res_list
res_list$Search %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
res_list$Search
class(res_list$Search)
title <- "Groundhog Day" %>% URLencode()
endpoint <- "http://www.omdbapi.com/"
url <- paste0(endpoint, "?", "t=", title, "&tomatoes=true")
omdb_res = GET(url)
res_list <- content(omdb_res, as =  "parsed")
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
url <- paste0(endpoint, "?t=", title, "&tomatoes=true")
omdb_res = GET(url)
res_list <- content(omdb_res, as =  "parsed")
res_list %>% unlist() %>% t() %>% data.frame(stringsAsFactors = FALSE)
url <- paste0(endpoint, "?s=", title)
omdb_res = GET(url)
res_list <- content(omdb_res, as = "text") %>% jsonlite::fromJSON(flatten = TRUE)
res_list$Search
apikey <- "&appid=42c7829f663f87eb05d2f12ab11f2b5d"
url <- paste0(endpoint, "q=", city, apikey)
city <- "Chicago,IL"
url <- paste0(endpoint, "q=", city, apikey)
url
GET(URL)
GET(url)
weather_res <- GET(url)
class(weather_res)
res_list <- content(weather_res, as =  "parsed")
res_list
endpoint <- "http://api.openweathermap.org/data/2.5/find?"
city <- "Chicago,IL"
url <- paste0(endpoint, "q=", city, apikey)
weather_res <- GET(url)
res_list <- content(weather_res, as =  "parsed")
res_list
res_list <- content(weather_res, as =  "text")  %>% jsonlite::fromJSON(flatten = TRUE)
res_list
res_list$list
metric <- "&units=metric"
url <- paste0(endpoint, "q=", city, metric, apikey)
weather_res <- GET(url)
res_list <- content(weather_res, as =  "parsed")
res_list <- content(weather_res, as =  "text")  %>% jsonlite::fromJSON(flatten = TRUE)
res_list$list
